{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gplearn.genetic import SymbolicRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# CSV 파일에서 데이터 로드\n",
    "file_path = '20240806_correlation_copy.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "normalized_data = scaler.fit_transform(df)\n",
    "\n",
    "normalized_df = pd.DataFrame(normalized_data, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0     9.62          5.13189        3         0.109358              N/A      2.01m\n",
      "   1     4.38         0.432124        8         0.102453              N/A      1.51m\n",
      "   2     3.18          0.22198        8         0.102453              N/A      1.32m\n",
      "   3     3.42         0.184312        5         0.100677              N/A      1.44m\n",
      "   4     6.24         0.237448       15          0.08306              N/A      1.26m\n",
      "   5     8.11         0.230324       15          0.08306              N/A      1.40m\n",
      "   6     9.36         0.204871       15        0.0777261              N/A      1.13m\n",
      "   7    13.27         0.176691       17        0.0722877              N/A      1.80m\n",
      "   8    15.67         0.170696       17        0.0712299              N/A      1.72m\n",
      "   9    17.20         0.151181       17        0.0712299              N/A      1.45m\n",
      "  10    17.95         0.151674       31        0.0675517              N/A      1.36m\n",
      "  11    18.52         0.152071       23        0.0615571              N/A      1.86m\n",
      "  12    19.33          0.15799       23        0.0615571              N/A      1.48m\n",
      "  13    24.57          0.13362       18        0.0586841              N/A      1.60m\n",
      "  14    27.30         0.132201       18        0.0586841              N/A      1.51m\n",
      "  15    27.16         0.120988       26         0.053799              N/A      1.25m\n",
      "  16    30.40         0.119573       18        0.0504577              N/A      1.37m\n",
      "  17    35.22         0.119019       41         0.049669              N/A      1.46m\n",
      "  18    37.02         0.108113       41         0.049669              N/A      1.54m\n",
      "  19    37.65         0.154421       41         0.049669              N/A      1.41m\n",
      "  20    38.67          0.10113       54        0.0494363              N/A      1.34m\n",
      "  21    30.49         0.127043       59        0.0492171              N/A      1.41m\n",
      "  22    25.13         0.133736       62        0.0490802              N/A      1.23m\n",
      "  23    20.88         0.139416       68        0.0490664              N/A      1.34m\n",
      "  24    19.00         0.150445       44         0.049943              N/A      1.44m\n",
      "  25    18.00         0.147987       37        0.0492672              N/A      1.37m\n",
      "  26    18.22         0.140705       18        0.0504577              N/A      1.24m\n",
      "  27    17.23          0.13922       17        0.0504577              N/A     58.73s\n",
      "  28    16.74         0.141339       17        0.0504577              N/A      1.20m\n",
      "  29    17.05         0.141464       17        0.0504577              N/A      1.26m\n",
      "  30    17.36         0.142163       17        0.0504577              N/A      1.20m\n",
      "  31    17.14          0.14183       17        0.0504577              N/A      1.11m\n",
      "  32    16.88         0.151207       17        0.0504577              N/A      1.07m\n",
      "  33    16.95         0.143503       17        0.0504577              N/A      1.12m\n",
      "  34    16.73         0.145633       17        0.0504577              N/A      1.10m\n",
      "  35    17.01         0.150775       17        0.0504577              N/A      1.11m\n",
      "  36    16.97          0.14425       17        0.0504577              N/A     56.52s\n",
      "  37    16.72         0.153156       17        0.0504577              N/A     53.31s\n",
      "  38    17.73         0.134942       17        0.0504577              N/A     52.91s\n",
      "  39    16.74         0.139746       17        0.0504577              N/A     58.72s\n",
      "  40    17.27         0.144771       17        0.0504577              N/A     50.70s\n",
      "  41    16.90         0.141959       17        0.0504577              N/A     50.24s\n",
      "  42    16.90         0.147306       17        0.0504577              N/A     49.26s\n",
      "  43    17.03         0.139237       17        0.0504577              N/A     57.55s\n",
      "  44    16.80         0.144038       17        0.0504577              N/A     58.33s\n",
      "  45    17.29         0.141669       17        0.0504577              N/A     44.09s\n",
      "  46    16.79         0.144269       17        0.0504577              N/A     44.21s\n",
      "  47    17.03         0.142155       17        0.0504577              N/A     47.39s\n",
      "  48    17.20         0.148466       17        0.0504577              N/A     41.77s\n",
      "  49    17.01         0.138499       17        0.0504577              N/A     44.79s\n",
      "  50    16.92         0.143175       17        0.0504577              N/A     40.63s\n",
      "  51    17.24         0.144384       17        0.0504577              N/A     43.51s\n",
      "  52    17.11         0.137752       17        0.0504577              N/A     39.54s\n",
      "  53    17.48           0.1403       17        0.0504577              N/A     39.97s\n",
      "  54    16.80         0.140165       26        0.0495508              N/A     37.08s\n",
      "  55    17.12         0.139836       27         0.048756              N/A     40.22s\n",
      "  56    18.23         0.140655       36        0.0456871              N/A     37.70s\n",
      "  57    19.93         0.132972       36        0.0456871              N/A     39.44s\n",
      "  58    23.11         0.128698       36        0.0456871              N/A     41.82s\n",
      "  59    27.91         0.116614       36        0.0456871              N/A     55.74s\n",
      "  60    32.10         0.104002       36        0.0456871              N/A     47.44s\n",
      "  61    34.30        0.0976371       66        0.0456425              N/A     44.34s\n",
      "  62    36.67        0.0891925       58         0.045453              N/A     38.68s\n",
      "  63    36.22        0.0950283       49        0.0456547              N/A     35.03s\n",
      "  64    36.15        0.0954481       36        0.0456871              N/A     34.53s\n",
      "  65    35.36        0.0993249       82        0.0453281              N/A     37.04s\n",
      "  66    36.69        0.0925273       36        0.0456871              N/A     32.31s\n",
      "  67    36.82         0.101602       64        0.0456022              N/A     31.05s\n",
      "  68    35.96        0.0958826       58         0.045453              N/A     30.50s\n",
      "  69    35.65        0.0942151       36        0.0456871              N/A     30.61s\n",
      "  70    35.70        0.0899857       36        0.0456871              N/A     28.41s\n",
      "  71    37.18        0.0912074       36        0.0456871              N/A     27.34s\n",
      "  72    36.66        0.0936684       36        0.0456871              N/A     28.26s\n",
      "  73    36.92        0.0886053       36        0.0456871              N/A     25.78s\n",
      "  74    36.44        0.0914284       36        0.0456871              N/A     23.74s\n",
      "  75    36.50        0.0944837       36        0.0456871              N/A     22.98s\n",
      "  76    36.10         0.089156       36        0.0456871              N/A     23.92s\n",
      "  77    35.32        0.0956423       36        0.0456871              N/A     20.22s\n",
      "  78    35.08        0.0966061       36        0.0456871              N/A     25.14s\n",
      "  79    35.65        0.0914134       36        0.0456871              N/A     20.89s\n",
      "  80    35.92         0.093772       74        0.0455685              N/A     19.32s\n",
      "  81    37.02        0.0953637       74        0.0453715              N/A     18.00s\n",
      "  82    35.43         0.094403       56        0.0453701              N/A     17.83s\n",
      "  83    35.76        0.0976287       56        0.0453701              N/A     16.81s\n",
      "  84    36.32         0.100597       36        0.0456871              N/A     14.82s\n",
      "  85    36.56        0.0934571       36        0.0456871              N/A     13.90s\n",
      "  86    35.95        0.0987777       36        0.0453406              N/A     13.46s\n",
      "  87    36.20        0.0921966       36        0.0456871              N/A     11.52s\n",
      "  88    35.81        0.0967095       56        0.0453701              N/A     10.85s\n",
      "  89    36.38        0.0934865       36        0.0456871              N/A      9.83s\n",
      "  90    36.28        0.0960537       48        0.0446644              N/A      9.44s\n",
      "  91    36.24        0.0931678       66        0.0456123              N/A      7.93s\n",
      "  92    36.23        0.0930463       36        0.0456871              N/A      6.63s\n",
      "  93    36.81        0.0934276       36        0.0456871              N/A      6.15s\n",
      "  94    37.27        0.0921785       36        0.0456871              N/A      5.23s\n",
      "  95    35.49        0.0925086       72        0.0455045              N/A      3.75s\n",
      "  96    35.59        0.0953736       36        0.0456871              N/A      2.88s\n",
      "  97    36.32        0.0948566       36        0.0456871              N/A      2.09s\n",
      "  98    37.01        0.0962734       36        0.0456871              N/A      0.97s\n",
      "  99    36.26        0.0976721       36        0.0456871              N/A      0.00s\n",
      "sqrt(sqrt(mul(X0, sub(sub(sqrt(sqrt(sqrt(sub(sqrt(sub(X10, sqrt(sqrt(sqrt(sqrt(sqrt(sub(sqrt(sub(X10, sqrt(sqrt(sqrt(sub(sqrt(sqrt(sub(X10, 0.930))), X0)))))), X0)))))))), X0)))), X0), X1))))\n"
     ]
    }
   ],
   "source": [
    "y_min, y_max = df[\"reduction_S0 (kcal/mol)\"].min(), df[\"reduction_S0 (kcal/mol)\"].max()\n",
    "\n",
    "X = normalized_df[[\"homo (eV)\", \"vertical_excitation_energy (eV)\", \"dipole_moment_norm_S0 (D)\",\n",
    "    \"dipole_moment_norm_S1 (D)\", \"dipole_moment_norm_T1 (D)\",\"0-0_S1 (eV)\", \"0-0_T1 (eV)\",\n",
    "    \"adiabatic_S1-S0 (kcal/mol)\", \"adiabatic_T1-S0 (kcal/mol)\", \"oxidation_S0 (kcal/mol)\",\n",
    "    \"lumo-homo (eV)\"]]\n",
    "y = normalized_df[\"reduction_S0 (kcal/mol)\"]\n",
    "\n",
    "est = SymbolicRegressor(population_size=1000,\n",
    "                        generations=100,\n",
    "                        stopping_criteria=0.01,\n",
    "                        function_set=['add', 'sub', 'mul', 'div', 'sqrt', 'log', 'abs', 'neg', 'inv'],\n",
    "                        metric='mean absolute error',\n",
    "                        parsimony_coefficient=0.0001,\n",
    "                        verbose=1,\n",
    "                        random_state=0)\n",
    "\n",
    "est.fit(X, y)\n",
    "\n",
    "# 수식 출력\n",
    "if hasattr(est, '_program'):\n",
    "    print(est._program)\n",
    "else:\n",
    "    print(\"The model does not have a _program attribute.\")\n",
    "\n",
    "y_pred_normalized = est.predict(X)\n",
    "y_pred = y_pred_normalized * (y_max - y_min) + y_min\n",
    "y_actual = y * (y_max - y_min) + y_min\n",
    "\n",
    "r2 = r2_score(y_actual, y_pred)\n",
    "mae = MAE(y_actual, y_pred)\n",
    "rmse = np.sqrt(MSE(y_actual, y_pred))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot([y_min, y_max], [y_min, y_max], 'k-', lw=2)\n",
    "plt.scatter(y_actual, y_pred, color = 'red', alpha=0.5)\n",
    "plt.xlabel(f'Actual values of reduction_S0 (kcal/mol)')\n",
    "plt.ylabel(f'Predicted values of reduction_S0 (kcal/mol)')\n",
    "plt.title('Parity Plot of reduction_S0 (kcal/mol)')\n",
    "\n",
    "# R^2 값 그래프에 추가\n",
    "plt.text(x=0.05, y=0.95, s=f'$R^2 = {r2:.4f}$', fontsize=12, ha='left', va='top', transform=plt.gca().transAxes)\n",
    "plt.text(x=0.05, y=0.90, s=f'MAE = {mae:.4f} (kcal/mol)', fontsize=12, ha='left', va='top', transform=plt.gca().transAxes)\n",
    "plt.text(x=0.05, y=0.85, s=f'RMSE = {rmse:.4f} (kcal/mol)', fontsize=12, ha='left', va='top', transform=plt.gca().transAxes)\n",
    "\n",
    "# 그래프 이미지 파일로 저장\n",
    "plt.savefig('GPlearn Reduction1.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0     9.15          3.73027        3         0.105092         0.112811      3.71m\n",
      "   1     4.58          0.45382        8        0.0837923        0.0892862      3.03m\n",
      "   2     4.00         0.337527        7        0.0836444        0.0906112      3.52m\n",
      "   3     4.50         0.343613        9        0.0777149         0.077287      3.34m\n",
      "   4     6.82         0.232589       10        0.0583384        0.0558641      2.70m\n",
      "   5     7.75         0.197281       10        0.0578475        0.0602647      3.22m\n",
      "   6     8.29         0.224602       10        0.0572159        0.0659265      3.25m\n",
      "   7     8.90         0.356308       11        0.0572149        0.0659356      3.50m\n",
      "   8     9.22         0.449017        9        0.0568182        0.0694912      3.75m\n",
      "   9     9.00         0.568221        8        0.0569378          0.06671      3.21m\n",
      "  10     8.21          0.49337        7        0.0567914        0.0680224      3.06m\n",
      "  11     7.40         0.354352        6        0.0567675         0.068237      2.74m\n",
      "  12     6.93         0.290952        6        0.0566333        0.0694393      2.64m\n",
      "  13     6.57         0.247108        7        0.0566549        0.0692464      2.89m\n",
      "  14     6.53         0.247361        6        0.0565839        0.0698827      3.47m\n",
      "  15     6.35         0.236813        6        0.0567019        0.0688249      2.49m\n",
      "  16     6.27         0.231669        6        0.0567473        0.0684178      2.45m\n",
      "  17     6.09         0.232622        6        0.0566801        0.0690201      2.56m\n",
      "  18     6.07         0.230114        6        0.0566821         0.069002      2.37m\n",
      "  19     6.02         0.295698        6        0.0566872        0.0689562      2.42m\n",
      "  20     6.05         0.231025        6        0.0566035         0.069707      2.31m\n",
      "  21     5.97         0.235961        6        0.0568376        0.0676082      2.37m\n",
      "  22     5.89         0.240998        6        0.0566766        0.0690513      2.42m\n",
      "  23     6.05         0.266954        6        0.0567843        0.0680862      2.67m\n",
      "  24     6.04         0.242377        6        0.0566752        0.0690643      2.62m\n",
      "  25     6.00         0.236812        6        0.0567355        0.0685239      2.39m\n",
      "  26     5.91         0.244248        6        0.0568547        0.0674547      2.46m\n",
      "  27     5.88         0.244128        6        0.0567078        0.0687722      2.17m\n",
      "  28     5.98         0.238366        6        0.0566519        0.0692733      2.60m\n",
      "  29     5.93         0.256861        6        0.0567114        0.0687394      2.65m\n",
      "  30     5.91         0.265412        6        0.0568844        0.0671889      2.60m\n",
      "  31     5.97           0.2502        6        0.0568117        0.0678404      2.11m\n",
      "  32     5.89         0.238129        6        0.0567626        0.0682807      2.08m\n",
      "  33     5.99         0.253005        6        0.0567537        0.0683606      2.50m\n",
      "  34     5.93         0.291773        6        0.0566263        0.0695022      2.01m\n",
      "  35     5.96         0.284054        6        0.0567217        0.0686472      2.12m\n",
      "  36     5.97         0.231797        6        0.0567564        0.0683365      2.03m\n",
      "  37     5.90         0.252713        6         0.056706        0.0687883      2.20m\n",
      "  38     5.90         0.238991        6        0.0564979        0.0706529      1.93m\n",
      "  39     5.84         0.245489        6        0.0566904         0.068928      2.20m\n",
      "  40     5.98         0.244997        6        0.0566377        0.0693998      2.20m\n",
      "  41     5.83         0.232514        6        0.0567459        0.0684303      1.91m\n",
      "  42     5.99         0.233238        6        0.0567811        0.0681145      2.00m\n",
      "  43     5.99         0.279954        6         0.056746        0.0684298      1.85m\n",
      "  44     6.00         0.291887        6        0.0568985        0.0670627      1.84m\n",
      "  45     5.88         0.256861        6        0.0567883        0.0680499      1.65m\n",
      "  46     5.97         0.291658        6        0.0568869        0.0671664      1.86m\n",
      "  47     6.01         0.254563        6        0.0564387         0.071184      1.75m\n",
      "  48     5.97         0.242019        6        0.0566553        0.0692425      1.84m\n",
      "  49     5.96         0.250964        6        0.0566909        0.0689229      2.01m\n",
      "  50     5.96         0.230771        6        0.0569056        0.0669985      1.59m\n",
      "  51     5.95         0.266805        6        0.0565917        0.0698121      1.79m\n",
      "  52     5.92         0.273664        6        0.0567343        0.0685342      1.49m\n",
      "  53     5.93         0.243112        6        0.0566501        0.0692893      1.59m\n",
      "  54     5.89         0.229201        6        0.0568589        0.0674175      1.88m\n",
      "  55     5.98         0.238399        6         0.056766        0.0682503      1.53m\n",
      "  56     5.95         0.254265        6        0.0568416        0.0675723      1.70m\n",
      "  57     5.91         0.233904        6        0.0567925        0.0680127      1.58m\n",
      "  58     5.93         0.249777        6        0.0567799        0.0681253      1.47m\n",
      "  59     5.87         0.307819        6        0.0569925        0.0662195      1.35m\n",
      "  60     5.96         0.234606        6        0.0566285        0.0694826      1.51m\n",
      "  61     5.91         0.241364        6        0.0564552        0.0710357      1.40m\n",
      "  62     5.84         0.270087        6        0.0569204        0.0668664      1.53m\n",
      "  63     6.02         0.257494        6        0.0566358        0.0694168      1.77m\n",
      "  64     5.94         0.266766        6        0.0566181        0.0695763      1.48m\n",
      "  65     5.97         0.298658        6        0.0567289        0.0685825      1.37m\n",
      "  66     6.00         0.249335        6        0.0568265        0.0677076      1.18m\n",
      "  67     5.81         0.229272        6        0.0566509        0.0692823      1.20m\n",
      "  68     5.94         0.241258        6        0.0565003        0.0706322      1.46m\n",
      "  69     5.98          0.23772        6         0.056742        0.0684657      1.11m\n",
      "  70     5.93         0.246853        6        0.0567054        0.0687934      1.35m\n",
      "  71     6.01         0.244801        6        0.0565378        0.0702953      1.03m\n",
      "  72     5.92         0.280081        6         0.056574        0.0699709     54.33s\n",
      "  73     5.98         0.247648        6        0.0566574        0.0692235     50.80s\n",
      "  74     5.89         0.237011        6        0.0564493         0.071089     46.86s\n",
      "  75     5.92         0.237661        6        0.0565876         0.069849     45.54s\n",
      "  76     5.89         0.234226        6        0.0567322        0.0685531     40.90s\n",
      "  77     5.99         0.247458        6        0.0567907        0.0680284     39.87s\n",
      "  78     5.89         0.256613        6        0.0562084         0.073248     38.51s\n",
      "  79     5.98          0.24081        6        0.0568666        0.0673487     39.43s\n",
      "  80     5.91         0.226304        6        0.0567326        0.0685498     38.80s\n",
      "  81     5.87         0.237512        6        0.0566191        0.0695668     50.30s\n",
      "  82     5.93         0.228992        6        0.0568942        0.0671011     32.02s\n",
      "  83     5.88         0.271727        6        0.0568516        0.0674829     28.25s\n",
      "  84     5.98          0.24762        6        0.0567226        0.0686389     35.04s\n",
      "  85     5.98          0.23548        6        0.0564681        0.0709207     27.38s\n",
      "  86     5.88         0.240096        6        0.0564684        0.0709174     30.93s\n",
      "  87     5.95         0.235209        6        0.0566568        0.0692292     29.77s\n",
      "  88     5.98         0.233413        6        0.0567621        0.0682854     25.94s\n",
      "  89     5.97         0.261507        6         0.056677        0.0690476     21.24s\n",
      "  90     5.87         0.249948        6         0.056683        0.0689943     19.76s\n",
      "  91     5.93         0.265021        6        0.0564468        0.0711118     17.34s\n",
      "  92     5.88         0.271751        6        0.0566849        0.0689769     14.04s\n",
      "  93     6.01         0.250993        6        0.0565352        0.0703187     11.27s\n",
      "  94     5.98         0.230614        6        0.0567301        0.0685717     10.46s\n",
      "  95     5.91         0.240542        6        0.0565433        0.0702463      7.70s\n",
      "  96     5.92         0.227702        6        0.0565819           0.0699      6.51s\n",
      "  97     6.05         0.238717        6        0.0567856        0.0680743      3.60s\n",
      "  98     5.91         0.263593        6        0.0568244        0.0677266      2.22s\n",
      "  99     5.97         0.256463        6        0.0564505        0.0710783      0.00s\n",
      "sqrt(sqrt(sub(X9, sqrt(X10))))\n"
     ]
    }
   ],
   "source": [
    "y_min, y_max = df[\"reduction_S0 (kcal/mol)\"].min(), df[\"reduction_S0 (kcal/mol)\"].max()\n",
    "\n",
    "X = normalized_df[[\"homo (eV)\", \"vertical_excitation_energy (eV)\", \"dipole_moment_norm_S0 (D)\",\n",
    "    \"dipole_moment_norm_S1 (D)\", \"dipole_moment_norm_T1 (D)\",\"0-0_S1 (eV)\", \"0-0_T1 (eV)\",\n",
    "    \"adiabatic_S1-S0 (kcal/mol)\", \"adiabatic_T1-S0 (kcal/mol)\", \"oxidation_S0 (kcal/mol)\",\n",
    "    \"lumo-homo (eV)\"]]\n",
    "y = normalized_df[\"reduction_S0 (kcal/mol)\"]\n",
    "\n",
    "est = SymbolicRegressor(population_size=2000,\n",
    "                           generations=100, stopping_criteria=0.01,\n",
    "                           function_set=['add', 'sub', 'mul', 'div', 'sqrt', 'log', 'abs', 'neg', 'inv'],\n",
    "                           p_crossover=0.7, p_subtree_mutation=0.1,\n",
    "                           p_hoist_mutation=0.05, p_point_mutation=0.1,\n",
    "                           max_samples=0.9, verbose=1,\n",
    "                           parsimony_coefficient=0.0001, random_state=0)\n",
    "\n",
    "est.fit(X, y)\n",
    "\n",
    "# 수식 출력\n",
    "print(est._program)\n",
    "\n",
    "y_pred_normalized = est.predict(X)\n",
    "y_pred = y_pred_normalized * (y_max - y_min) + y_min\n",
    "y_actual = y * (y_max - y_min) + y_min\n",
    "\n",
    "r2 = r2_score(y_actual, y_pred)\n",
    "mae = MAE(y_actual, y_pred)\n",
    "rmse = np.sqrt(MSE(y_actual, y_pred))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot([y_min, y_max], [y_min, y_max], 'k-', lw=2)\n",
    "plt.scatter(y_actual, y_pred, color = 'red', alpha=0.5)\n",
    "plt.xlabel(f'Actual values of reduction_S0 (kcal/mol)')\n",
    "plt.ylabel(f'Predicted values of reduction_S0 (kcal/mol)')\n",
    "plt.title('Parity Plot of reduction_S0 (kcal/mol)')\n",
    "\n",
    "# R^2 값 그래프에 추가\n",
    "plt.text(x=0.05, y=0.95, s=f'$R^2 = {r2:.4f}$', fontsize=12, ha='left', va='top', transform=plt.gca().transAxes)\n",
    "plt.text(x=0.05, y=0.90, s=f'MAE = {mae:.4f} (kcal/mol)', fontsize=12, ha='left', va='top', transform=plt.gca().transAxes)\n",
    "plt.text(x=0.05, y=0.85, s=f'RMSE = {rmse:.4f} (kcal/mol)', fontsize=12, ha='left', va='top', transform=plt.gca().transAxes)\n",
    "\n",
    "# 그래프 이미지 파일로 저장\n",
    "plt.savefig('GPlearn Reduction2.png')\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
